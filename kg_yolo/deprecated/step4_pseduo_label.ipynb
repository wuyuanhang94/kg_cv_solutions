{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import detectron2\n",
    "from tqdm.auto import tqdm\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.evaluation import inference_on_dataset\n",
    "from detectron2.evaluation.evaluator import DatasetEvaluator\n",
    "from detectron2.data import DatasetCatalog, build_detection_test_loader\n",
    "import pycocotools.mask as mask_util\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from ensemble_boxes import *\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' \n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "    print('GPU is available')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    print('CPU is used')\n",
    "print('detectron ver:', detectron2.__version__)\n",
    "\n",
    "train = glob.glob(\"/home/yiw/kg/input/train/*\")\n",
    "test = glob.glob(\"/home/yiw/kg/input/test/*\")\n",
    "\n",
    "annotations = {}\n",
    "\n",
    "# Open the annotations file\n",
    "with open('/home/yiw/kg/input/polygons.jsonl', 'r') as f:\n",
    "    for line in f:\n",
    "        annotation = json.loads(line)\n",
    "        image_id = annotation['id']\n",
    "        image_annotations = annotation['annotations']\n",
    "        annotations[image_id] = image_annotations\n",
    "\n",
    "image_map = {impath.split('/')[-1].split('.')[0]: impath for impath in train}\n",
    "unlabelled_id = image_map.keys() - annotations.keys()\n",
    "\n",
    "config_name = \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"\n",
    "mdl_path = \"/home/yiw/kg/output\"\n",
    "DATA_PATH = \"/home/yiw/kg/input/\"\n",
    "MODELS = []\n",
    "BEST_MODELS =[]\n",
    "THSS = []\n",
    "ID_TEST = 0\n",
    "SUBM_PATH = f'{DATA_PATH}/train'\n",
    "SINGLE_MODE = False\n",
    "NMS = True\n",
    "IOU_TH = .6\n",
    "\n",
    "THRESHOLDS = [.5, .99]\n",
    "MIN_PIXELS = [1, 60]\n",
    "\n",
    "best_model = [\"model_best.pth\"]\n",
    "\n",
    "for b_m in best_model:\n",
    "    model_name=b_m\n",
    "    model_ths=THRESHOLDS\n",
    "    BEST_MODELS.append(model_name)\n",
    "    THSS.append(model_ths)\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(config_name))\n",
    "    cfg.INPUT.MASK_FORMAT = 'bitmask'\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2\n",
    "    cfg.MODEL.WEIGHTS = f'{mdl_path}/{model_name}'\n",
    "\n",
    "    cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[16], [32], [64], [128], [256]]\n",
    "    cfg.MODEL.ASPECT_RATIOS = [[0.25, 0.5, 1.0, 2.0, 4.0]]\n",
    "    cfg.MODEL.RPN.IN_FEATURES = ['p2', 'p3', 'p4', 'p5', 'p6']\n",
    "    cfg.MODEL.SEM_SEG_HEAD.IN_FEATURES = ['p2', 'p3', 'p4', 'p5', 'p6']\n",
    "\n",
    "    cfg.INPUT.MIN_SIZE_TEST = 512\n",
    "    cfg.INPUT.MAX_SIZE_TEST = 1280\n",
    "\n",
    "    cfg.TEST.DETECTIONS_PER_IMAGE = 1000\n",
    "    MODELS.append(DefaultPredictor(cfg))\n",
    "print(f'all loaded:\\nthresholds: {THSS}\\nmodels: {BEST_MODELS}')\n",
    "print(MODELS)\n",
    "\n",
    "def rle_decode(mask_rle, shape=(512, 512)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) \n",
    "                       for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo : hi] = 1\n",
    "    return img.reshape(shape)  # Needed to align to RLE direction\n",
    "\n",
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    \n",
    "    '''\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def pred_masks(file_name, path, model, ths, min_pixels):\n",
    "    img = cv2.imread(f'{path}/{file_name}')\n",
    "    output = model(img)\n",
    "    pred_classes = output['instances'].pred_classes.cpu().numpy().tolist()\n",
    "    pred_class = max(set(pred_classes), key=pred_classes.count)\n",
    "    take = output['instances'].scores >= ths[pred_class]\n",
    "    pred_masks = output['instances'].pred_masks[take]\n",
    "    pred_masks = pred_masks.cpu().numpy()\n",
    "    result = []\n",
    "    used = np.zeros(img.shape[:2], dtype=int) \n",
    "    for i, mask in enumerate(pred_masks):\n",
    "        mask = mask * (1 - used)\n",
    "        if mask.sum() >= min_pixels[pred_class]:\n",
    "            used += mask\n",
    "            result.append(rle_encode(mask))\n",
    "    return result\n",
    "\n",
    "def ensemble_preds(file_name, path, models, ths):\n",
    "    img = cv2.imread(f'{path}/{file_name}')\n",
    "    \n",
    "    outputs = []\n",
    "    \n",
    "    classes = []\n",
    "    scores = []\n",
    "    bboxes = []\n",
    "    masks = []\n",
    "    \n",
    "    pred_classes_gros = []\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        output = model(img)\n",
    "        outputs.append(output)\n",
    "        \n",
    "        pred_classes = output['instances'].pred_classes.cpu().numpy().tolist()\n",
    "        pred_class = max(set(pred_classes), key=pred_classes.count)\n",
    "        #print(f\"old model {i} predict class {pred_class}\")\n",
    "        pred_classes_gros.append(pred_class)\n",
    "    \n",
    "    pred_class_final = max(set(pred_classes_gros), key=pred_classes_gros.count)\n",
    "    #print(f\"final class {pred_class_final}\")\n",
    "    \n",
    "    for c, output in zip(pred_classes_gros, outputs):\n",
    "        if c != pred_class_final:\n",
    "            continue\n",
    "        take = output['instances'].scores >= ths[i][pred_class_final]\n",
    "        classes.extend(output['instances'].pred_classes[take].cpu().numpy().tolist())\n",
    "        scores.extend(output['instances'].scores[take].cpu().numpy().tolist())\n",
    "        bboxes.extend(output['instances'].pred_boxes[take].tensor.cpu().numpy().tolist())\n",
    "        masks.extend(output['instances'].pred_masks[take].cpu().numpy())\n",
    "\n",
    "    assert len(classes) == len(masks) , 'ensemble lenght mismatch'\n",
    "    return classes, scores, bboxes, masks\n",
    "\n",
    "def nms_predictions(classes, scores, bboxes, masks, \n",
    "                    iou_th=.5, shape=(512, 512)):\n",
    "    he, wd = shape[0], shape[1]\n",
    "    boxes_list = [[[x[0] / wd, x[1] / he, x[2] / wd, x[3] / he] for x in bboxes]]\n",
    "    scores_list = [[x for x in scores]]\n",
    "    classes_list = [[x for x in classes]]\n",
    "    nms_bboxes, nms_scores, nms_classes = non_maximum_weighted(\n",
    "        boxes_list, \n",
    "        scores_list, \n",
    "        classes_list, \n",
    "        weights=None,\n",
    "        iou_thr=IOU_TH,\n",
    "        skip_box_thr=0.0001,\n",
    "    )\n",
    "    nms_masks = []\n",
    "    for s in nms_scores:\n",
    "        nms_masks.append(masks[scores.index(s)])\n",
    "    nms_scores, nms_classes, nms_masks = zip(*sorted(zip(nms_scores, nms_classes, nms_masks), reverse=True))\n",
    "    return nms_classes, nms_scores, nms_masks\n",
    "\n",
    "def ensemble_pred_masks(masks, classes, min_pixels, shape=(512, 512)):\n",
    "    result = []\n",
    "    #pred_class = max(set(classes), key=classes.count)\n",
    "    pred_class = int(max(set(classes), key=classes.count).item())\n",
    "    used = np.zeros(shape, dtype=int) \n",
    "    for i, mask in enumerate(masks):\n",
    "        mask = mask * (1 - used)\n",
    "        if mask.sum() >= min_pixels[pred_class]:\n",
    "            used += mask\n",
    "            result.append(rle_encode(mask))\n",
    "    return result\n",
    "\n",
    "test_names = [f\"{image_id}.tif\" for image_id in unlabelled_id]\n",
    "print('test images:', len(test_names))\n",
    "\n",
    "encoded_masks_single = pred_masks(\n",
    "    test_names[ID_TEST], \n",
    "    path=SUBM_PATH, \n",
    "    model=MODELS[0],\n",
    "    ths=THSS[ID_TEST],\n",
    "    min_pixels=MIN_PIXELS\n",
    ")\n",
    "\n",
    "classes, scores, bboxes, masks = ensemble_preds(\n",
    "    file_name=test_names[ID_TEST] , \n",
    "    path=SUBM_PATH, \n",
    "    models=MODELS, \n",
    "    ths=THSS\n",
    ")\n",
    "if NMS:\n",
    "    classes, scores, masks = nms_predictions(\n",
    "        classes, \n",
    "        scores, \n",
    "        bboxes,\n",
    "        masks, iou_th=IOU_TH\n",
    "    )\n",
    "encoded_masks = ensemble_pred_masks(masks, classes, min_pixels=MIN_PIXELS)\n",
    "\n",
    "_, axs = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axs[0][0].imshow(cv2.imread(f'{SUBM_PATH}/{test_names[ID_TEST]}'))\n",
    "axs[0][0].axis('on')\n",
    "axs[0][0].set_title(test_names[ID_TEST])\n",
    "for en_mask in encoded_masks_single:\n",
    "    dec_mask = rle_decode(en_mask)\n",
    "    axs[0][1].imshow(np.ma.masked_where(dec_mask == 0, dec_mask))\n",
    "    axs[0][1].axis('on')\n",
    "    axs[0][1].set_title('single model')\n",
    "axs[1][0].imshow(cv2.imread(f'{SUBM_PATH}/{test_names[ID_TEST]}'))\n",
    "axs[1][0].axis('on')\n",
    "axs[1][0].set_title(test_names[ID_TEST])\n",
    "for en_mask in encoded_masks:\n",
    "    dec_mask = rle_decode(en_mask)\n",
    "    axs[1][1].imshow(np.ma.masked_where(dec_mask == 0, dec_mask))\n",
    "    axs[1][1].axis('on')\n",
    "    axs[1][1].set_title('ensemble models')\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "#from tqdm.notebook import tqdm\n",
    "import json, itertools\n",
    "idx = 0\n",
    "cats =[{'name': \"blood_vessel\", 'id':1}, {'name': \"unsure\", \"id\": 2}]\n",
    "images = [{'id':image_id, 'width': 512, 'height': 512, 'file_name': image_map[image_id]} for image_id in annotations.keys()]\n",
    "coco_annotations = []\n",
    "\n",
    "def binary_mask_to_rle(binary_mask):\n",
    "    rle = {'counts': [], 'size': list(binary_mask.shape)}\n",
    "    counts = rle.get('counts')\n",
    "    for i, (value, elements) in enumerate(itertools.groupby(binary_mask.ravel(order='F'))):\n",
    "        if i == 0 and value == 1:\n",
    "            counts.append(0)\n",
    "        counts.append(len(list(elements)))\n",
    "    return rle\n",
    "\n",
    "for test_name in tqdm(test_names):\n",
    "    img = cv2.imread(f'{SUBM_PATH}/{test_name}')\n",
    "    h, w, _ = img.shape\n",
    "    if SINGLE_MODE:\n",
    "        encoded_masks = pred_masks(\n",
    "            test_name, \n",
    "            path=SUBM_PATH, \n",
    "            model=MODELS[0],\n",
    "            ths=THSS[0],\n",
    "            min_pixels=MIN_PIXELS\n",
    "        )\n",
    "    else:\n",
    "        classes, scores, bboxes, masks = ensemble_preds(\n",
    "            file_name=test_name, \n",
    "            path=SUBM_PATH, \n",
    "            models=MODELS, \n",
    "            ths=THSS\n",
    "        )\n",
    "        for clss, mk in zip(classes, masks):\n",
    "            ys, xs = np.where(mk)\n",
    "            x1, x2 = min(xs), max(xs)\n",
    "            y1, y2 = min(ys), max(ys)\n",
    "            enc = binary_mask_to_rle(mk)\n",
    "            seg = {\n",
    "                'segmentation':enc, \n",
    "                'bbox': [int(x1), int(y1), int(x2-x1+1), int(y2-y1+1)],\n",
    "                'bbox_mode': 1,\n",
    "                'area': int(np.sum(mk)),\n",
    "                'image_id': image_id, \n",
    "                'category_id': 1,\n",
    "                'iscrowd': 0, \n",
    "                'id': idx\n",
    "            }\n",
    "            coco_annotations.append(seg)\n",
    "            idx += 1\n",
    "\n",
    "images = [{'id':image_id, 'width': 512, 'height': 512, 'file_name': image_map[image_id]} for image_id in unlabelled_id]\n",
    "final_coco_annos = {'categories':cats, 'images':images,'annotations': coco_annotations}\n",
    "\n",
    "with open(f'pseduo_label.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(final_coco_annos, f, ensure_ascii=True, indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6ff6d93c7d79f342dac0d02922526e4297c5fb34d893e0ad67d099f62d0db73"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
