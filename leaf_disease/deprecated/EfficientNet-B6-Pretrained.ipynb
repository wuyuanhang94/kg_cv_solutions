{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm as tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from efficientnet_b6 import *\n",
    "from printing import progress_bar\n",
    "\n",
    "data_path = os.path.abspath(os.path.join(os.path.curdir, 'input/cassava-leaf-disease-classification'))\n",
    "train_path = os.path.join(data_path, 'train_images')\n",
    "label_path = os.path.join(data_path, 'train.csv')\n",
    "test_path = os.path.join(data_path, 'test_images')\n",
    "csv_path = os.path.join(data_path, 'sample_submission.csv')\n",
    "cwd = os.path.abspath('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'fold_num': 5,\n",
    "    'seed': 899,\n",
    "    'model_arch': 'efficientnet-b6',\n",
    "    'image_size': 512,\n",
    "    'epochs': 100,\n",
    "    'train_batch_size': 1,\n",
    "    'val_batch_size': 2,\n",
    "    'T_0': 10,\n",
    "    'lr': 1e-4,\n",
    "    'min_lr': 1e-6,\n",
    "    'weight_decay': 1e-6,\n",
    "    'num_workers': 1,\n",
    "    'device': 'cuda:0'\n",
    "}\n",
    "\n",
    "dataset_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "                    transforms.Resize((528, 528)),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.RandomVerticalFlip(),\n",
    "                    transforms.RandomRotation(30),\n",
    "                    transforms.RandomCrop((528, 528), padding=3),\n",
    "                    transforms.ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2), saturation=(0.8, 1.2)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.4304, 0.4968, 0.3135], [0.2358, 0.2387, 0.2256])\n",
    "                ]),\n",
    "    'other': transforms.Compose([\n",
    "                    transforms.Resize((528, 528)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.4304, 0.4968, 0.3135], [0.2358, 0.2387, 0.2256])\n",
    "                ])\n",
    "}\n",
    "\n",
    "device = cfg['device']\n",
    "best_acc = .0\n",
    "label_df = pd.read_csv(label_path)\n",
    "\n",
    "freq_ = dict(len(label_df) / label_df['label'].value_counts())\n",
    "weights = torch.zeros(5)\n",
    "for k, v in freq_.items():\n",
    "    weights[k] = v\n",
    "weights = weights.to(device)\n",
    "\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CassavaDataset(Dataset):\n",
    "    def __init__(self, df, dPath=None, transforms=None, test=False):\n",
    "        super(CassavaDataset, self).__init__()\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.dPath = dPath\n",
    "        self.transforms = transforms\n",
    "        self.test = test\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.df['image_id'].values[idx]\n",
    "        img_path = os.path.join(self.dPath, img_name)\n",
    "        img = Image.open(img_path)\n",
    "        if self.test:\n",
    "            label = int(img_name.split('.')[0])\n",
    "        else:\n",
    "            img = self.transforms(img)\n",
    "            label = self.df['label'].values[idx]\n",
    "        return img, label\n",
    "\n",
    "def prepare_dataloader(label_df, train_idx, val_idx):\n",
    "    train_df = label_df.loc[train_idx, :].reset_index(drop=True)\n",
    "    val_df = label_df.loc[val_idx, :].reset_index(drop=True)\n",
    "    \n",
    "    train_dataset = CassavaDataset(train_df, train_path, dataset_transforms['train'])\n",
    "    val_dataset = CassavaDataset(val_df, train_path, dataset_transforms['other'])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=cfg['train_batch_size'], shuffle=True, num_workers=cfg['num_workers'])\n",
    "    val_loader = DataLoader(val_dataset, batch_size=cfg['val_batch_size'], shuffle=False, num_workers=cfg['num_workers'])\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, net, optimizer, scheduler, criterion):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        progress_bar(batch_idx, len(train_loader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                     % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "def validate(epoch, val_loader, net, optimizer, criterion):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, labels) in enumerate(val_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            progress_bar(batch_idx, len(val_loader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                         % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving...')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir(os.path.join(cwd, 'checkpoint')):\n",
    "            os.mkdir(os.path.join(cwd, 'checkpoint'))\n",
    "        torch.save(state, os.path.join(cwd, 'checkpoint/leaf-b6.pth'))\n",
    "        best_acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th fold training starts...\n",
      "Loaded pretrained weights for efficientnet-b6\n",
      "\n",
      "Epoch: 0\n",
      "[>.............................]Step:74ms | Tot:2s577ms | Loss: 1.608 | Acc: 34.722% (25/72)     \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a612c5e1c5c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-a612c5e1c5c3>\u001b[0m in \u001b[0;36mmain_loop\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nEpoch: %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-370cdcb40790>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(epoch, val_loader, net, optimizer, criterion)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mtest_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main_loop():\n",
    "    folds = StratifiedKFold(n_splits=cfg['fold_num'], shuffle=True, random_state=cfg['seed'])\n",
    "    folds = folds.split(np.arange(label_df.shape[0]), label_df.label.values)\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(folds):\n",
    "        print(f'{fold}th fold training starts...')\n",
    "        \n",
    "        train_loader, val_loader = prepare_dataloader(label_df, train_idx, val_idx)\n",
    "        net = EfficientNet.from_pretrained('efficientnet-b6').to(device)\n",
    "        net._fc = nn.Linear(net._fc.in_features, 5)\n",
    "        net = torch.nn.DataParallel(net)\n",
    "        \n",
    "        optimizer = optim.Adam(net.parameters(), lr=cfg['lr'], weight_decay=cfg['weight_decay'])\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=cfg['T_0'], T_mult=1, eta_min=cfg['min_lr'], last_epoch=-1)\n",
    "        criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "        \n",
    "        for epoch in range(cfg['epochs']):\n",
    "            print('\\nEpoch: %d' % epoch)\n",
    "            validate(epoch, val_loader, net, optimizer, criterion)\n",
    "            train(train_loader, net, optimizer, scheduler, criterion)\n",
    "\n",
    "main_loop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
