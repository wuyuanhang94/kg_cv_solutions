{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tifffile as tiff\n",
    "import cv2\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import zipfile\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import gc\n",
    "import glob\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from albumentations import (Compose, Normalize)\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def enc2mask(encs, shape):\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for m,enc in enumerate(encs):\n",
    "        if isinstance(enc,np.float) and np.isnan(enc): continue\n",
    "        s = enc.split()\n",
    "        for i in range(len(s)//2):\n",
    "            start = int(s[2*i]) - 1\n",
    "            length = int(s[2*i+1])\n",
    "            img[start:start+length] = 1 + m\n",
    "    return img.reshape(shape).T\n",
    "\n",
    "def mask2enc(mask, n=1):\n",
    "    pixels = mask.T.flatten()\n",
    "    encs = []\n",
    "    for i in range(1,n+1):\n",
    "        p = (pixels == i).astype(np.int8)\n",
    "        if p.sum() == 0: encs.append(np.nan)\n",
    "        else:\n",
    "            p = np.concatenate([[0], p, [0]])\n",
    "            runs = np.where(p[1:] != p[:-1])[0] + 1\n",
    "            runs[1::2] -= runs[::2]\n",
    "            encs.append(' '.join(str(x) for x in runs))\n",
    "    return encs\n",
    "\n",
    "def rle_encode_less_memory(img):\n",
    "    pixels = img.T.flatten()\n",
    "    pixels[0] = 0\n",
    "    pixels[-1] = 0\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def make_grid(shape, window=1024, min_overlap=256):\n",
    "    x, y = shape\n",
    "    nx = x // (window - min_overlap) + 1\n",
    "    x1 = np.linspace(0, x, num=nx, endpoint=False, dtype=np.int64)\n",
    "    x1[-1] = x - window\n",
    "    x2 = (x1 + window).clip(0, x)\n",
    "    ny = y // (window - min_overlap) + 1\n",
    "    y1 = np.linspace(0, y, num=ny, endpoint=False, dtype=np.int64)\n",
    "    y1[-1] = y - window\n",
    "    y2 = (y1 + window).clip(0, y)\n",
    "    slices = np.zeros((nx, ny, 4), dtype=np.int64)\n",
    "\n",
    "    for i in range(nx):\n",
    "        for j in range(ny):\n",
    "            slices[i, j] = x1[i], x2[i], y1[j], y2[j]\n",
    "    return slices.reshape(nx * ny, 4)\n",
    "\n",
    "sz = 512\n",
    "reduce = 2\n",
    "min_overlap = 256\n",
    "s_th = 40\n",
    "p_th = 1000 * (sz//256) ** 2\n",
    "identity = rasterio.Affine(1, 0, 0, 0, 1, 0)\n",
    "\n",
    "DATA = '../input/hubmap-kidney-segmentation/test/'\n",
    "df_sample = pd.read_csv('../input/hubmap-kidney-segmentation/sample_submission.csv')\n",
    "device = 'cuda'\n",
    "\n",
    "mean_512 = np.array([0.63990417, 0.4734721, 0.68480998])\n",
    "std_512 = np.array([0.16061672, 0.22722983, 0.14034663])\n",
    "\n",
    "def img2tensor(img, dtype:np.dtype=np.float32):\n",
    "    if img.ndim == 2:\n",
    "        img = np.expand_dims(img, 2)\n",
    "    img = np.transpose(img, (2, 0, 1))\n",
    "    return torch.from_numpy(img.astype(dtype, copy=False))\n",
    "\n",
    "class HubMAPDataset(Dataset):\n",
    "    def __init__(self, idx, sz, reduce, mean, std):\n",
    "        self.data = rasterio.open(os.path.join(DATA, idx+'.tiff'), transform=identity, num_threads='all_cpus')\n",
    "        if self.data.count != 3:\n",
    "            subdatasets = self.data.subdatasets\n",
    "            self.layers = []\n",
    "            if len(subdatasets) > 0:\n",
    "                for i, subdataset in enumerate(subdatasets, 0):\n",
    "                    self.layers.append(rasterio.open(subdataset))\n",
    "        self.shape = self.data.shape\n",
    "        self.reduce = reduce\n",
    "        self.sz = reduce * sz\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.make_grid = make_grid(self.shape, window=self.sz, min_overlap=min_overlap)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.make_grid)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = np.zeros((self.sz, self.sz, 3), np.uint8)\n",
    "\n",
    "        x1, x2, y1, y2 = self.make_grid[idx]\n",
    "        if self.data.count == 3:\n",
    "            img = self.data.read([1, 2, 3], window=Window.from_slices((x1, x2), (y1, y2)))\n",
    "            img = np.moveaxis(img, 0, -1)\n",
    "        else:\n",
    "            for i, layer in enumerate(self.layers):\n",
    "                img[:, :, i] = layer.read(1, window=Window.from_slices((x1, x2), (y1, y2)))\n",
    "        \n",
    "        if self.reduce != 1:\n",
    "            img = cv2.resize(img, (self.sz//self.reduce, self.sz//self.reduce), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        h, s, v = cv2.split(hsv)\n",
    "        \n",
    "        vertices = torch.tensor([x1, x2, y1, y2])\n",
    "\n",
    "        if (s > s_th).sum() <= p_th or img.sum() <= p_th:\n",
    "            return img2tensor((img / 255.0 - self.mean) / self.std), -1, vertices\n",
    "        else:\n",
    "            return img2tensor((img / 255.0 - self.mean) / self.std), idx, vertices\n",
    "\n",
    "net512s = []\n",
    "# unetb3\n",
    "for model in glob.glob('../input/unetb3dcs512/*.pth'):\n",
    "    net = smp.Unet(encoder_name='timm-efficientnet-b3', encoder_weights=None, classes=1, activation=None)\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    net = net.cuda()\n",
    "    checkpoint = torch.load(model)\n",
    "    net.load_state_dict(checkpoint['net'])\n",
    "    net.eval()\n",
    "    net512s.append(net)\n",
    "\n",
    "def inference(x, y, vertices, tta=False):\n",
    "    py = None\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    print(vertices.shape)\n",
    "    with torch.no_grad():\n",
    "        if ((y >= 0).sum() > 0): #exclude empty images\n",
    "            x = x[y >= 0].to(device)\n",
    "            y = y[y >= 0]\n",
    "            vertices = vertices[y >= 0]\n",
    "            print(x.shape)\n",
    "            print(y.shape)\n",
    "            print(vertices.shape)\n",
    "\n",
    "            for model in net512s:\n",
    "                p = model(x)\n",
    "                p = torch.sigmoid(p).detach()\n",
    "                if py is None:\n",
    "                    py = p.detach()\n",
    "                else:\n",
    "                    py += p.detach()      \n",
    "            py /= len(net512s)\n",
    "            py = py.permute(0, 2, 3, 1)\n",
    "            py = py.squeeze().cpu().numpy()\n",
    "    return py\n",
    "\n",
    "def submission():\n",
    "    names, preds = [], []\n",
    "    for idx, row in tqdm(df_sample.iterrows(), total=len(df_sample)):\n",
    "        ds_512 = HubMAPDataset(idx=row['id'], sz=512, reduce=2, mean=mean_512, std=std_512)\n",
    "        test_loader_512 = DataLoader(ds_512, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "        \n",
    "        preds = np.zeros(ds_512.shape, dtype=np.float16)\n",
    "        for (x, y, vertices) in test_loader_512:\n",
    "            pred = inference(x, y, vertices)\n",
    "            if pred is None: continue\n",
    "            for j, p in enumerate(pred):\n",
    "                p = cv2.resize(p, (1024, 1024))\n",
    "                x1, x2, y1, y2 = vertices[j]\n",
    "                preds[x1:x2, y1:y2] += p\n",
    "\n",
    "        mask = (preds >= 0.4)\n",
    "        rle = rle_encode_less_memory(mask.numpy())\n",
    "\n",
    "        names.append(row['id'])\n",
    "        preds.append(rle)\n",
    "        del preds, mask, ds_512, ds, test_loader_512\n",
    "        gc.collect()\n",
    "\n",
    "    df = pd.DataFrame({'id': names, 'predicted': preds})\n",
    "    df.to_csv('submission.csv',index=False)\n",
    "    return df\n",
    "\n",
    "df = submission()\n"
   ]
  }
 ]
}