{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d34b456c18dc4434bdaa7f9fa1976ebd"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (1024) must match the size of tensor b (2048) at non-singleton dimension 3",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2101433c5c5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m         \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.35\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-2101433c5c5c>\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m                     \u001b[0mp_256\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bilinear\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                     \u001b[0mpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp_512\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp_256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m                     \u001b[0mpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (1024) must match the size of tensor b (2048) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tifffile as tiff\n",
    "import cv2\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import zipfile\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import gc\n",
    "import glob\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from albumentations import (Compose, Normalize)\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sz = 512\n",
    "reduce = 2\n",
    "DATA = 'input/test/'\n",
    "df_sample = pd.read_csv('input/sample_submission.csv')\n",
    "\n",
    "def enc2mask(encs, shape):\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for m,enc in enumerate(encs):\n",
    "        if isinstance(enc,np.float) and np.isnan(enc): continue\n",
    "        s = enc.split()\n",
    "        for i in range(len(s)//2):\n",
    "            start = int(s[2*i]) - 1\n",
    "            length = int(s[2*i+1])\n",
    "            img[start:start+length] = 1 + m\n",
    "    return img.reshape(shape).T\n",
    "\n",
    "def mask2enc(mask, n=1):\n",
    "    pixels = mask.T.flatten()\n",
    "    encs = []\n",
    "    for i in range(1,n+1):\n",
    "        p = (pixels == i).astype(np.int8)\n",
    "        if p.sum() == 0: encs.append(np.nan)\n",
    "        else:\n",
    "            p = np.concatenate([[0], p, [0]])\n",
    "            runs = np.where(p[1:] != p[:-1])[0] + 1\n",
    "            runs[1::2] -= runs[::2]\n",
    "            encs.append(' '.join(str(x) for x in runs))\n",
    "    return encs\n",
    "\n",
    "def rle_encode_less_memory(img):\n",
    "    pixels = img.T.flatten()\n",
    "    pixels[0] = 0\n",
    "    pixels[-1] = 0\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "s_th = 40\n",
    "p_th = 1000 * (sz//256) ** 2\n",
    "identity = rasterio.Affine(1, 0, 0, 0, 1, 0)\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "mean = np.array([0.63759809, 0.4716141, 0.68231112])\n",
    "std = np.array([0.16475244, 0.22850685, 0.14593643])\n",
    "\n",
    "def img2tensor(img, dtype:np.dtype=np.float32):\n",
    "    if img.ndim == 2:\n",
    "        img = np.expand_dims(img, 2)\n",
    "    img = np.transpose(img, (2, 0, 1))\n",
    "    return torch.from_numpy(img.astype(dtype, copy=False))\n",
    "\n",
    "class HubMAPDataset(Dataset):\n",
    "    def __init__(self, idx, sz=sz, reduce=reduce):\n",
    "        self.data = rasterio.open(os.path.join(DATA, idx+'.tiff'), transform=identity, num_threads='all_cpus')\n",
    "        if self.data.count != 3:\n",
    "            subdatasets = self.data.subdatasets\n",
    "            self.layers = []\n",
    "            if len(subdatasets) > 0:\n",
    "                for i, subdataset in enumerate(subdatasets, 0):\n",
    "                    self.layers.append(rasterio.open(subdataset))\n",
    "        self.shape = self.data.shape\n",
    "        self.reduce = reduce\n",
    "        self.sz = reduce * sz #1024\n",
    "        self.pad0 = (self.sz - self.shape[0]%self.sz) % self.sz # x方向pad\n",
    "        self.pad1 = (self.sz - self.shape[1]%self.sz) % self.sz # y方向pad\n",
    "        self.n0max = (self.shape[0] + self.pad0) // self.sz # x反向最多多少个patch\n",
    "        self.n1max = (self.shape[1] + self.pad1) // self.sz # y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n0max * self.n1max\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        n0, n1 = idx//self.n1max, idx%self.n1max\n",
    "        x0, y0 = -self.pad0//2 + n0*self.sz, -self.pad1//2 + n1*self.sz\n",
    "        p00, p01 = max(0, x0), min(x0+self.sz, self.shape[0])\n",
    "        p10, p11 = max(0, y0), min(y0+self.sz, self.shape[1])\n",
    "        img = np.zeros((self.sz, self.sz, 3), np.uint8)\n",
    "\n",
    "        if self.data.count == 3:\n",
    "            img[(p00-x0):(p01-x0),(p10-y0):(p11-y0)] = np.moveaxis(self.data.read([1,2,3],\n",
    "                window=Window.from_slices((p00,p01),(p10,p11))), 0, -1)\n",
    "        else:\n",
    "            for i,layer in enumerate(self.layers):\n",
    "                img[(p00-x0):(p01-x0),(p10-y0):(p11-y0),i] =\\\n",
    "                  layer.read(1,window=Window.from_slices((p00,p01),(p10,p11)))\n",
    "        \n",
    "        if self.reduce != 1:\n",
    "            img = cv2.resize(img,(self.sz//reduce,self.sz//reduce),\n",
    "                             interpolation = cv2.INTER_AREA)\n",
    "\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        h, s, v = cv2.split(hsv)\n",
    "\n",
    "        if (s > s_th).sum() <= p_th or img.sum() <= p_th:\n",
    "            return img2tensor((img / 255.0 - mean) / std), -1\n",
    "        else:\n",
    "            return img2tensor((img / 255.0 - mean) / std), idx\n",
    "\n",
    "class Model_pred:\n",
    "    def __init__(self, net512s:None, dl, tta:bool=False, half:bool=False):\n",
    "        self.net512s = net512s\n",
    "        self.net256s = net256s\n",
    "        self.dl = dl\n",
    "        self.tta = tta\n",
    "        self.half = half\n",
    "        \n",
    "    def __iter__(self):\n",
    "        count=0\n",
    "        with torch.no_grad():\n",
    "            for x, y in iter(self.dl):\n",
    "                if ((y >= 0).sum() > 0): #exclude empty images\n",
    "                    x = x[y >= 0].to(device)\n",
    "                    y = y[y >= 0]\n",
    "\n",
    "                    py = None                    \n",
    "                    for model in self.net512s:\n",
    "                        p = model(x)\n",
    "                        p = torch.sigmoid(p).detach()\n",
    "                        if py is None: py = p.detach()\n",
    "                        else: py += p.detach()      \n",
    "                    py /= len(self.net512s)\n",
    "                    \n",
    "                    py = F.upsample(py, scale_factor=2, mode=\"bilinear\")\n",
    "                    py = py.permute(0,2,3,1).float().cpu()\n",
    "                    \n",
    "                    batch_size = len(py)\n",
    "                    for i in range(batch_size):\n",
    "                        yield py[i],y[i]\n",
    "                        count += 1\n",
    "                    \n",
    "    def __len__(self):\n",
    "        return len(self.dl.dataset)\n",
    "\n",
    "def inference(ds, test_loader, nets):\n",
    "    mask = torch.zeros(len(ds), ds.sz, ds.sz, dtype=torch.int8)\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            if ((y >= 0).sum() > 0): #exclude empty images\n",
    "                x = x[y >= 0].to(device)\n",
    "                y = y[y >= 0]\n",
    "\n",
    "                py = None                    \n",
    "                for model in nets:\n",
    "                    p = model(x)\n",
    "                    p = torch.sigmoid(p).detach()\n",
    "                    if py is None:\n",
    "                        py = p.detach()\n",
    "                    else:\n",
    "                        py += p.detach()      \n",
    "                py /= len(nets)\n",
    "                \n",
    "                py = F.upsample(py, scale_factor=2, mode=\"bilinear\")\n",
    "                py = py.permute(0, 2, 3, 1).float().cpu()\n",
    "            \n",
    "                valid_mask = len(py)\n",
    "                for i in range(valid_mask):\n",
    "                    mask[y[i]] = (py[i].squeeze(-1) >= 0.39)\n",
    "    return mask\n",
    "\n",
    "net512s = []\n",
    "for model in glob.glob('checkpoint/*512*.pth'):\n",
    "    net = smp.Unet(encoder_name='timm-efficientnet-b4', encoder_weights=None, classes=1, activation=None)\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    net = net.cuda()\n",
    "    checkpoint = torch.load(model)\n",
    "    net.load_state_dict(checkpoint['net'])\n",
    "    net.eval()\n",
    "    net512s.append(net)\n",
    "\n",
    "net256s = []\n",
    "for model in glob.glob('checkpoint/*fpn*.pth'):\n",
    "    net = smp.FPN(encoder_name='timm-efficientnet-b4', encoder_weights=None, classes=1, activation=None)\n",
    "    checkpoint = torch.load(model)\n",
    "    net.load_state_dict(checkpoint['net'])\n",
    "    net = net.cuda()\n",
    "    net.eval()\n",
    "    net256s.append(net)\n",
    "\n",
    "def submission_generator():\n",
    "    names, preds = [], []\n",
    "    for idx, row in tqdm(df_sample.iterrows(), total=len(df_sample)):\n",
    "        ds = HubMAPDataset(idx=row['id'], sz=512, reduce=2)\n",
    "        test_loader = DataLoader(ds, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "        mp = Model_pred(net512s, dl=test_loader)\n",
    "        \n",
    "        mask = torch.zeros(len(ds), ds.sz, ds.sz, dtype=torch.int8)\n",
    "        for p, i in iter(mp):\n",
    "            mask[i.item()] = p.squeeze(-1) >= 0.35\n",
    "        \n",
    "        mask = mask.view(ds.n0max, ds.n1max, ds.sz, ds.sz).\\\n",
    "            permute(0, 2, 1, 3).reshape(ds.n0max * ds.sz, ds.n1max * ds.sz)\n",
    "        mask = mask[ds.pad0 // 2 : -(ds.pad0 - ds.pad0 // 2)\\\n",
    "                        if ds.pad0 > 0 else ds.n0max*ds.sz,\n",
    "                    ds.pad1//2:-(ds.pad1-ds.pad1//2)\\\n",
    "                        if ds.pad1 > 0 else ds.n1max*ds.sz]\n",
    "        \n",
    "        rle = rle_encode_less_memory(mask.numpy())\n",
    "\n",
    "        names.append(row['id'])\n",
    "        preds.append(rle)\n",
    "        del mask, ds, test_loader\n",
    "        gc.collect()\n",
    "\n",
    "    df = pd.DataFrame({'id': names, 'predicted': preds})\n",
    "    df.to_csv('submission.csv',index=False)\n",
    "    return df\n",
    "\n",
    "def submission():\n",
    "    names, preds = [], []\n",
    "    for idx, row in tqdm(df_sample.iterrows(), total=len(df_sample)):\n",
    "        ds = HubMAPDataset(idx=row['id'], sz=512, reduce=2)\n",
    "        test_loader = DataLoader(ds, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "        \n",
    "        mask = inference(ds, test_loader, net512s)\n",
    "        mask = mask.view(ds.n0max, ds.n1max, ds.sz, ds.sz).\\\n",
    "            permute(0, 2, 1, 3).reshape(ds.n0max * ds.sz, ds.n1max * ds.sz)\n",
    "        mask = mask[ds.pad0 // 2 : -(ds.pad0 - ds.pad0 // 2)\\\n",
    "                        if ds.pad0 > 0 else ds.n0max*ds.sz,\n",
    "                    ds.pad1//2:-(ds.pad1-ds.pad1//2)\\\n",
    "                        if ds.pad1 > 0 else ds.n1max*ds.sz]\n",
    "        \n",
    "        rle = rle_encode_less_memory(mask.numpy())\n",
    "\n",
    "        names.append(row['id'])\n",
    "        preds.append(rle)\n",
    "        del mask, ds, test_loader\n",
    "        gc.collect()\n",
    "\n",
    "    df = pd.DataFrame({'id': names, 'predicted': preds})\n",
    "    df.to_csv('submission.csv',index=False)\n",
    "    return df\n",
    "\n",
    "# df = submission_generator()\n",
    "df = submission()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          id                                          predicted\n",
       "0  2ec3f1bb9  60738309 24 60762290 39 60786274 48 60810258 5...\n",
       "1  3589adb90  68600092 16 68600120 34 68629517 75 68658947 8...\n",
       "2  d488c759a  535323817 19 535370474 26 535417130 36 5354637...\n",
       "3  aa05346ff  52764540 19 52795254 32 52825970 41 52856687 4...\n",
       "4  57512b7f1  328886086 2 328919318 29 328952554 40 32898579..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>predicted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2ec3f1bb9</td>\n      <td>60738309 24 60762290 39 60786274 48 60810258 5...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3589adb90</td>\n      <td>68600092 16 68600120 34 68629517 75 68658947 8...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>d488c759a</td>\n      <td>535323817 19 535370474 26 535417130 36 5354637...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>aa05346ff</td>\n      <td>52764540 19 52795254 32 52825970 41 52856687 4...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>57512b7f1</td>\n      <td>328886086 2 328919318 29 328952554 40 32898579...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../submission.csv')\n",
    "df"
   ]
  }
 ]
}