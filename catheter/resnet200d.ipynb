{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":["import sys\n","sys.path.append('../input/timm-package/pytorch-image-models-master')\n","\n","import os\n","import cv2\n","import timm\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.transforms as transforms\n","from torch.utils.data import Dataset, DataLoader\n","import torch.optim as optim\n","import torch.backends.cudnn as cudnn\n","\n","from albumentations import (\n","    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90, ElasticTransform,\n","    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n","    IAAAdditiveGaussianNoise, GaussNoise, GaussianBlur, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n","    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout,\n","    ShiftScaleRotate, CenterCrop, Resize, GridDropout\n",")\n","from albumentations.pytorch import ToTensorV2\n","\n","cfg = {\n","    'model_arch': 'resnet200d',\n","    'img_size': 512,\n","    'batch_size': 16,\n","    'target_size': 11,\n","    'target_cols': ['ETT - Abnormal', 'ETT - Borderline', 'ETT - Normal',\n","                    'NGT - Abnormal', 'NGT - Borderline', 'NGT - Incompletely Imaged', 'NGT - Normal', \n","                    'CVC - Abnormal', 'CVC - Borderline', 'CVC - Normal',\n","                    'Swan Ganz Catheter Present'],\n","    'device': 'cuda',\n","}\n","device = cfg['device']\n","\n","data_path = os.path.abspath(os.path.join(os.path.pardir, 'input/ranzcr-clip-catheter-line-classification'))\n","train_path = os.path.join(data_path, 'train')\n","label_path = os.path.join(data_path, 'train.csv')\n","test_path = os.path.join(data_path, 'test')\n","csv_path = os.path.join(data_path, 'sample_submission.csv')\n","cwd = os.path.abspath('.')\n","cudnn.benchmark = True\n","\n","def get_img(img_path):\n","    img_bgr = cv2.imread(img_path)\n","    return img_bgr[..., ::-1]\n","\n","def get_valid_transforms(img_size=700):\n","    return Compose([\n","            Resize(img_size, img_size),\n","            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","            ToTensorV2(p=1.0),\n","        ], p=1.0)\n","\n","class CatheterDataset(Dataset):\n","    def __init__(self, df, dPath=None, transforms=None):\n","        super(CatheterDataset, self).__init__()\n","        self.df = df.reset_index(drop=True)\n","        self.dPath = dPath\n","        self.transforms = transforms\n","\n","    def __len__(self):\n","        return self.df.shape[0]\n","\n","    def __getitem__(self, idx):\n","        uid = self.df['StudyInstanceUID'].values[idx]\n","        img_name = uid + '.jpg'\n","        img_path = os.path.join(self.dPath, img_name)\n","        image = get_img(img_path)\n","        augmented = self.transforms(image=image)\n","        img = augmented['image']\n","        return img\n","    \n","class CustomResNet200D(nn.Module):\n","    def __init__(self, model_name=cfg['model_arch']):\n","        super().__init__()\n","        self.model = timm.create_model(model_name)\n","        n_features = self.model.fc.in_features\n","        self.model.global_pool = nn.Identity()\n","        self.model.fc = nn.Identity()\n","        self.pooling = nn.AdaptiveAvgPool2d(1)\n","        self.fc = nn.Linear(n_features, 11)\n","\n","    def forward(self, x):\n","        features = self.model(x)\n","        pooled_features = self.pooling(features).view(x.size(0), -1)\n","        output = self.fc(pooled_features)\n","        return output\n","    \n","class CustomInceptionv3(nn.Module):\n","    def __init__(self, model_name='inception_v3'):\n","        super().__init__()\n","        self.model = timm.create_model(model_name)\n","        n_features = self.model.fc.in_features\n","        self.model.global_pool = nn.Identity()\n","        self.model.fc = nn.Identity()\n","        self.pooling = nn.AdaptiveAvgPool2d(1)\n","        self.fc = nn.Linear(n_features, 11)\n","\n","    def forward(self, x):\n","        features = self.model(x)\n","        pooled_features = self.pooling(features).view(x.size(0), -1)\n","        output = self.fc(pooled_features)\n","        return output\n","    \n","class CustomEffb5(nn.Module):\n","    def __init__(self, model_name='tf_efficientnet_b5'):\n","        super().__init__()\n","        self.model = timm.create_model(model_name)\n","        n_features = self.model.classifier.in_features\n","        self.model.global_pool = nn.Identity()\n","        self.model.classifier = nn.Identity()\n","        self.pooling = nn.AdaptiveAvgPool2d(1)\n","        self.fc = nn.Linear(n_features, 11)\n","\n","    def forward(self, x):\n","        features = self.model(x)\n","        pooled_features = self.pooling(features).view(x.size(0), -1)\n","        output = self.fc(pooled_features)\n","        return output\n","\n","def inference(test_loader, nets):\n","    progress_bar = tqdm(enumerate(test_loader), total=len(test_loader))\n","    probs = []\n","    for net in nets:\n","        net.eval()\n","        net.to(device)\n","\n","    for batch_idx, images in progress_bar:\n","        images = images.to(device)\n","        avg_preds = []\n","        for net in nets:\n","            with torch.no_grad():\n","                y_preds1 = net(images)\n","                y_preds2 = net(images.flip(-1))\n","            y_preds = (y_preds1.sigmoid().to('cpu').numpy() + y_preds2.sigmoid().to('cpu').numpy()) / 2\n","            avg_preds.append(y_preds)\n","        avg_preds = np.mean(avg_preds, axis=0)\n","        probs.append(avg_preds)\n","    probs = np.concatenate(probs)\n","    return probs\n","\n","def submission():\n","    torch.cuda.empty_cache()\n","    predictions = []\n","    \n","    weights = {\n","        # resnet200d\n","        384: 0.12,\n","        512: 0.28,\n","        700: 0.36,\n","        # inception-v3\n","        640: 0.12\n","    }\n","    \n","    for dire, img_size in zip(('../input/size384', '../input/resnet200d-stage3', '../input/size700'), (384, 512, 700)):\n","        test_df = pd.read_csv(csv_path)\n","        test_set = CatheterDataset(test_df, test_path, get_valid_transforms(img_size=img_size))\n","        test_loader = DataLoader(test_set, batch_size=cfg['batch_size'], shuffle=False, num_workers=12)\n","        nets = []\n","        for name in os.listdir(dire):\n","            net = CustomResNet200D()\n","            net = torch.nn.DataParallel(net)\n","            checkpoint = torch.load(os.path.join(dire, name))\n","            net.load_state_dict(checkpoint['net'])\n","            net.eval()\n","            nets.append(net)\n","        p = inference(test_loader, nets)\n","        predictions.append(weights[img_size] * p)\n","        del test_loader, nets\n","        torch.cuda.empty_cache()\n","        \n","    for dire, img_size in zip(('../input/inception640',), (640,)):\n","        test_df = pd.read_csv(csv_path)\n","        test_set = CatheterDataset(test_df, test_path, get_valid_transforms(img_size=img_size))\n","        test_loader = DataLoader(test_set, batch_size=cfg['batch_size'], shuffle=False, num_workers=12)\n","        nets = []\n","        cfg['model_arch'] = 'inception_v3'\n","        for name in os.listdir(dire):\n","            net = CustomInceptionv3()\n","            net = torch.nn.DataParallel(net, device_ids=[0])\n","            checkpoint = torch.load(os.path.join(dire, name))\n","            net.load_state_dict(checkpoint['net'])\n","            net.eval()\n","            nets.append(net)\n","        p = inference(test_loader, nets)\n","        predictions.append(weights[img_size] * p)\n","        del test_loader, nets\n","        torch.cuda.empty_cache()\n","    \n","    for dire, img_size in zip(('../input/effnetb5',), (640,)):\n","        test_df = pd.read_csv(csv_path)\n","        test_set = CatheterDataset(test_df, test_path, get_valid_transforms(img_size=img_size))\n","        test_loader = DataLoader(test_set, batch_size=cfg['batch_size'], shuffle=False, num_workers=12)\n","        nets = []\n","        for name in os.listdir(dire):\n","            net = CustomEffb5()\n","            net = torch.nn.DataParallel(net, device_ids=[0])\n","            checkpoint = torch.load(os.path.join(dire, name))\n","            net.load_state_dict(checkpoint['net'])\n","            net.eval()\n","            nets.append(net)\n","        p = inference(test_loader, nets)\n","        weight = 0.12\n","        predictions.append(weight * p)\n","        del test_loader, nets\n","        torch.cuda.empty_cache()\n","        \n","    predictions = np.sum(predictions, axis=0)\n","    test_df[cfg['target_cols']] = predictions\n","    test_df[['StudyInstanceUID'] + cfg['target_cols']].to_csv('submission.csv', index=False)\n","    return test_df\n","\n","# df = submission()\n","# df\n","# for name in os.listdir('../input/size384'):\n","#     checkpoint = torch.load(f'../input/size384/{name}')\n","#     print(name, checkpoint['auc'])\n","# for name in os.listdir('../input/inception640'):\n","#     checkpoint = torch.load('../input/inception640/' + name)\n","#     print(name, checkpoint['auc'])"],"execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["directory = '../input/inception640/'\n","for name in os.listdir(directory):\n","    checkpoint = torch.load(directory + name)\n","    print(name, checkpoint['auc'])"],"execution_count":3,"outputs":[{"output_type":"stream","text":"catheter-inception_v3-student-fold1-auc.pth 0.9505887035976209\ncatheter-inception_v3-student-fold0-auc.pth 0.9508372489830479\ncatheter-inception_v3-student-fold2-auc.pth 0.9485751370863545\ncatheter-inception_v3-student-fold4-auc.pth 0.9519996432056795\ncatheter-inception_v3-student-fold3-auc.pth 0.9510773307614163\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":["directory = '../input/effnetb5/'\n","for name in os.listdir(directory):\n","    checkpoint = torch.load(directory + name)\n","    print(name, checkpoint['auc'])"],"execution_count":4,"outputs":[{"output_type":"stream","text":"catheter-tf_efficientnet_b5-student-fold1-auc.pth 0.9543205279911398\ncatheter-tf_efficientnet_b5-student-fold3-auc.pth 0.9468107697607795\ncatheter-tf_efficientnet_b5-student-fold4-auc.pth 0.9458153062659285\ncatheter-tf_efficientnet_b5-student-fold0-auc.pth 0.9572916930852879\ncatheter-tf_efficientnet_b5-student-fold2-auc.pth 0.951481841674983\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":["directory = '../input/size384/'\n","for name in os.listdir(directory):\n","    checkpoint = torch.load(directory + name)\n","    print(name, checkpoint['auc'])"],"execution_count":5,"outputs":[{"output_type":"stream","text":"catheter-resnet200d-student-fold3-auc.pth 0.9526698534855853\ncatheter-resnet200d-student-fold1-auc.pth 0.9551442535065647\ncatheter-resnet200d-student-fold0-auc.pth 0.9537666920863934\ncatheter-resnet200d-student-fold2-auc.pth 0.9502105538167304\ncatheter-resnet200d-student-fold4-auc.pth 0.95514839786041\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":["directory = '../input/size700/'\n","for name in os.listdir(directory):\n","    checkpoint = torch.load(directory + name)\n","    print(name, checkpoint['auc'])"],"execution_count":6,"outputs":[{"output_type":"stream","text":"catheter-resnet200d-student-fold2-700-auc.pth 0.9615204393214424\ncatheter-resnet200d-student-fold3-700-auc.pth 0.964261895294204\ncatheter-resnet200d-student-fold4-700-auc.pth 0.9659442361418951\ncatheter-resnet200d-student-fold0-700-auc.pth 0.9651744732864311\ncatheter-resnet200d-student-fold1-700-auc.pth 0.9640389998484064\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":["directory = '../input/resnet200d-stage3/'\n","for name in os.listdir(directory):\n","    checkpoint = torch.load(directory + name)\n","    print(name, checkpoint['auc'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["auc_l = [0.9505887035976209\n"," 0.9508372489830479\n",", 0.9485751370863545\n",", 0.9519996432056795\n",", 0.9510773307614163]"]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}